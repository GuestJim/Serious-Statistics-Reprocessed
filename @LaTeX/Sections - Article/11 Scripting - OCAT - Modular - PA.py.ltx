\section{Scripting: OCAT -- Modular -- PA.py}

As the title of this section suggests, we are now working on a Python script.
I have a certain love-hate relationship with Python, although it might be more accurately described as a satisfied-hate relationship.
This is mostly because its and my idiosyncrasies do not always align.
Still, making scripts like this gave me a reason to learn it and I would never describe the time as wasted.
I cannot imagine trying to recreate this script in something like BATCH, and while I have discovered R can handle some of this work directly, Python still has certain advantages to it, concerning drag-and-drop.

While abstractly there are similarities between Python and R, there are also a number of differences, so if you read the previous section, some concepts can be applied, but the semantics also have some important differences.
One very important thing to know is that when looking up items in a list by indices, R starts counting at 1 while Python starts at 0.
(Given a list [a, b, c], in R [a] is at 1 and in Python [a] is at 0.
It is not much fun to forget that when you are working on both at the same time, and suddenly something stops working.

First up in the script is what modules we are going to be loading.
(The similar concept in R is libraries.)

\subsubsection{Python Module Loading}
\begin{stylePy}
import sys, os, shutil
\end{stylePy}

These are the System, Operating System, and Shell Utility modules respectively, and each does have a purpose, but we might not be using them too much throughout the file.

\subsubsection{Script Arguments and File Paths}
\begin{stylePy}
droppedPath	=	sys.argv[1].rsplit("\\", 1)[0] + "\\"

scriptPath	=	sys.argv[0].rsplit("\\", 1)[0]
\end{stylePy}

These two lines are rather important to this script, and a number of others I have written.
The key is the \textbf{sys.argv} variable.
This is a list of the arguments passed to the Python script, with the first one (index 0) being the path to the script itself.
I keep the reference R scripts in the same folder, so the path to this script is useful.
The second element (index 1) is the path of the first file dropped onto the Python script.
If you drop more than one file on there, then their paths will be the following indices.
Regardless of the number, this allows me to drag-and-drop a file from the OCAT Data folder or the folders with the data in it, and this script will know where to look.
This is something I do not believe R is capable of, but even if it were, it would make certain things variables that I would prefer are fixed.

Following the \textbf{sys.argv[x]} variables is an actual function, \textbf{rsplit}, which stands for Reverse Split and is a string function.
Both the Split and reverse split functions will split a string at the pattern passed to it, which is "\DBS" here, and results in separating the individual directory names in the path to items in a list.
These functions can also take a second argument, 1 in both examples here, which is for how many splits to make.
For many functions in Python, the way you apply them to a variable is by placing a period between the variable and the function name.
It is also possible to chain together multiple functions like this, as we will see later.

The result here is to split the path and file names, because it is the paths to the files I want.
This is also why I am using reverse split, as it will start at the end of the path, where the file name is, and go backwards, thus the first split will be between the path and file name.
The result is a list with two elements, and the first element is the one I want; the path.
I attach "\DBS" at the end of both because it is necessary to close the path, as it were.

\subsubsection{Situation Check}
\begin{stylePy}
if "Review" in droppedPath.rsplit("OCAT Data")[0].rsplit("\\", 2)[1]:
	TYPE	=	"SINGLE"
elif "OCAT Data" in droppedPath.rsplit("\\", 4)[2:4]:
	TYPE	=	"MULTI"
else:
	TYPE	=	"SINGLE"
\end{stylePy}

This is a bit of a complicated statement, but it is actually a bit easier to read than another design I had been using.
You see, there are three situations I need to cover, and I have a check here for each: single-GPU review data; multi-GPU performance analysis; and single-GPU, multi-API performance analysis.
To determine the situation, this block of code examines the path of the file dropped onto the script.

To do this, I am using the \textbf{if}, \textbf{elif} and \textbf{else} commands.
The \textbf{if} and \textbf{else} commands work just as you would expect with any language.
The \textbf{elif} command is a shorthand command for \textit{else if}, which means that if the previous conditional was False (\textbf{else}), check this condition (\textbf{if}).

I also want to mention the semantic structure for Python here.
To identify the block of code to be run when an \textbf{if}, \textbf{else}, \textbf{elif}, or custom functions, as we will see, Python expects you to increase the tab indent beneath the command.
Personally I think this kind of tabbing is wise to use in most any language that allows it, as a way to efficiently indicate relations, but at times I also wish Python did not require it.
Anyway, it should also be noted that Python uses the colon character to identify when the block of code, the statement, to be run will be starting.

The first situation this covers is if we are working with data for a review, which is not too difficult because I always have the folder containing everything for a review labelled with "Review."
The complication that makes the conditional a bit more involved is that all reviews, performance analyses, and miscellaneous articles are contained in an "@Reviews" folder.
To address this, we need to check just the correct portion of the file path, which is easily achieved by using \textbf{rsplit} again, though the normal \textbf{split} function would work as well.
You see, within any article's directory, OCAT Data will be one of the top-level folders, so we can use that information to find just the article's folder name.
We split at "OCAT Data" and then split again by "\DBS" but only twice, giving us three elements.
The first is the path to the article's folder, the second is the name of the folder, and the third will be empty because the path ends with "\DBS" and there is nothing after it.
Remembering that indices start at zero, we use [1] to grab just the second element.
To test if "Review" is in the folder name, we use "in," which is fairly convenient.

Because the first condition tests for any reviews, the \textbf{elif} and \textbf{else} will only cover non-review articles.

The second situation is the multi-GPU situation for performance analyses, which is typically collecting all of the High Quality data together.
To collect this data, I drop a file from the OCAT Data folder onto the Python script, so the conditional is going to check where the file is relative to this folder.
To do this, we need to split the folder names again and check the last few.
The last one is always going to be empty though, because the path ends "\DBS".
That still leaves the conditional looking at two folder names instead of just one, but there is a reason for this.
Though it does not come up often, I may want to collect together data for one GPU across multiple APIs.
To achieve this I would drop a file from the specific GPU folder onto the script, so OCAT Data would be the folder above the dropped file.

If I am only looking at one GPU, why would I want \textbf{TYPE} to be "MULTI"?
Because with this value for \textbf{TYPE} the Python script will only collect the data for a specified quality level, usually High.
It might be single-GPU, but it is a multi-API situation so "MULTI" is what I want here.

There is also the situation of collecting the data of all quality levels together, but this basically never comes up.
I always break down performance by quality level so combining the data into single graphs or tables is not necessary.
If it comes up though, I could do some relatively simple manual work with other scripts to set this up.

The last bit of this code is to simply set \textbf{TYPE} to "SINGLE" if the previous conditional fails.
This covers the situation of collecting the data together for a specific configuration of GPU, API, and Quality, which is a single-GPU situation.

\subsubsection{Quality Selection for Multi-GPU Situation}
\begin{stylePy}
mQUA	=	"High"
\end{stylePy}

The easiest way to explain this is to identify that \textbf{mQUA} stands for multi-GPU quality, or multi-API quality.
Whenever \textbf{TYPE} is "MULTI" this means the script should collect just the data for a certain quality and this variable allows that to be quality to be controlled easily.
Previously I had "High" written in where the filtering of all data is done, but by creating this variable near the top of the file, finding and changing it is easier.

\subsubsection{listclean Custom Function}
\begin{stylePy}
def listclean	(list):
	return str(list).replace("[", "").replace("]", "").replace("\'", "\"").replace(", ", ",\n").replace(".csv", "");
\end{stylePy}

This is the first of two custom functions I have in this script.
Its purpose is to take a list from Python, make it a string, and then format it correctly for printing.
If all you do is convert a list to a string in Python, you will be left with brackets, single quotes, and the items in the list will be separated by commas and spaces.
Instead of that, I want a string that has each element on its own line, with a comma and line break separating them.
You can also see at the end I have it set to remove ".csv" from the string, which is fine because I have this added in the R script.
(Why do I not want the extension?
Because when I need to manually change or add a file name, it is just easier to do so without the extension.
This does not come up much anymore, but I do not feel like changing the scripts to keep the extension.)

To create a custom function in Python you use the \textbf{def} command, indicating you are defining something, and then you give it a name and the list of arguments.
As the purpose is to clean up a Python list, \textbf{listclean} is the name I chose and the only input needed is a list, so that is the name of the argument.

Like the \textbf{if} statement before, a colon is used to initiate the code block for what the function will do.
Instead of using a temporary variable, I use the \textbf{return} command immediately, so the code that follows it is what the function will return as its output.

The first part of this line of code is using the \textbf{str} command to turn the provided list into a string.
This string must then have some changes made to it, replacing some character patterns with others, so I used the aptly named \textbf{replace} command.
The first argument is the pattern to be replaced and the second is the pattern to replace it with.
For those cases where I just want to remove the pattern, I put nothing between the quotes used to denote the beginning and end of a string.
By the way, while I am using double quotes, Python also accepts single quotes for identifying strings, but the ends must be matching pairs.

To identify the elements of the list were strings, Python will place them in single quotes when making the list itself into a string, but I want double quotes.
I honestly do not know or remember if R cares between single and double quotes, but I have a preference for double quotes, so I have the single quotes replaced with double quotes here.
Because quotes are of meaning to Python, and many other languages, it is necessary to escape them, or rather escape their function, which is achieved with the "\SBS" symbol first.
Separating the elements is the pattern ", " and as I would prefer a line break to just a space, the replacement pattern is ",\n".
The "\n" symbol means to add a new line in strings in Python and many other languages too.
There is also "\r" that means carriage return and there is some importance to their differences, but here just "\n" is enough.
(Different operating systems will use different symbols for marking new lines, and at least on Windows, just this symbol is enough.)

To mark the end of the custom function's definition, a semicolon is used, so we close this out being just one line long.
The next custom function is a bit longer and a little more complicated.

\subsubsection{CSVlistR Custom Function}
\begin{stylePy}
def	CSVlistR	(GPU, API, QUA, CSVlist):
	if API	==	"NA":
		API	=	""
	return str("\
GPU	=	\"" + GPU + "\"\n\
CSV	=	c(\n"\
	+ listclean(CSVlist) + \
"\n)\n\
CSV	=	paste0(CSV, \".csv\")\n\
OCATcomb	=	READ(\"\", \"" + QUA + "\", \"" + API + "\")\n"
);
\end{stylePy}

This function is what will generate the R code block necessary for loading in the CSVs, hence its name \textbf{CSVlistR}.
It has four arguments, GPU, API, QUA for quality, and CSVlist for the actual list of CSVs that will be generated later.
Like before, a colon and tabbing is necessary to indicate the code block for the function.

The first part of the code block handles the case of no API being present in the data, which is the most common case actually.
You will see how I handle it later, but this function benefits from the collection of the files having already been done; I typically collect custom functions at the top of a file, but not always.
When no API is present, Python actually places NA as its value, so this checks if the value of the API is NA and will then set the value to be an empty string.
This is the simplest solution for how R should deal with a lack of API.

After this we have the return command and then things start getting complicated because of how I want the output formatted and Python being sensitive to formatting.
 By using the \textbf{str} command, we are indicating what is being built is a string.
The way to concatenate strings was actually shown earlier but I did not comment on it.
It is as simple as using the additive symbol.

It may seem odd and even broken that the contents of the \textbf{str} command are not indented to match the tab level for the code block, but this is because of how Python is sensitive.
If a tab or line break is in the body of the string, as it is written here, then Python will include it in the string itself.
Keeping things weird though, it is still necessary to use the escape symbol, "\SBS", so Python will properly handle line breaks, which is why the string starts with that character.

The first line of real content for the string needs to have no tab level to it, because I want it flush-left in the R script this will be placed in.
This line is for identifying the GPU for the data in the R script, and as this information will be a string, we need to place the information in quotes that will get to the R script.
This is why the double quotes that will surround the information are escaped, so Python will write them instead of acting on them.
The GPU variable is already a string, so it is just necessary to add the variable, by name, to the string for it to be present.
At the end of the line, in order to place a new line in the string, "\n" is used and then, so Python does not complain about the line break, another escape character is placed.

The next couple lines are for setting the CSV variable in R, which will hold the list of CSVs so we see the \textbf{listclean} function I defined above is here.
To tell R it will be a list, we will surround the list by \textbf{c()}, but to keep it easy to read, the actual list of file names starts on the line after we initiate the list in R.
We then just need to escape the line break in this Python script, add in the cleaned list, then add the remainder of the string.
Though it may look like the escape character will be added, Python basically will not even read it, or the character that follows.
Symbols like "\n", which are using the escape character are special so we are not escaping the "n" character.
Before closing the list in R, another new line is added so the lines with the file names on them will only contain the file names.

I should also point out that while there is a tab on the line for adding the CSV list, this tab is just there for it to be easier to read here, and will not actually be carried over to the R file as it is not in the string.
By keeping the tabs outside of the quotes for the string, it would be possible to indent the code to look nicer, but I do not feel like messing around with it that much.
There is already enough going on with the need to escape quotes within the string, using quotes to identify the strings, and escaping the line breaks that I do not want to get more fancy.

After closing the R list of files, another new line is added to the string and then another line break is used to keep things cleaner in the Python code.
The next line alters the CSV variable in R by pasting the ".csv" extension onto it, as the file names in the list are without this extension.
Quotes are escaped and another new line is added within the string to get to a custom R function I made named \textbf{READ}, which is in the \textit{OCAT – Combined – PA.r} script.
This function asks for the CSVs, GPU, Quality and API, so the arguments for this Python function are placed there so they will be supplied to R.

With that done, the \textbf{str} function can be ended with a parenthese and then the semicolon to end the custom function.

\subsubsection{Relative Path Creation}
\begin{stylePy}
RelPath	=	droppedPath.split("OCAT Data")[0] + "OCAT Data\\"
\end{stylePy}

The \textbf{RelPath} variable is meant for holding a relative path to everything, which would be the path to the OCAT Data folder, as all of the data is within it and its subfolders.
To get just the path to this folder, we can take advantage of the \textbf{split} function to separate \textbf{droppedPath} at OCAT Data.
This will produce a list with two elements in it, the first being the portion of \textbf{droppedPath} leading to the OCAT Data folder, while the second is the path after that folder, which might just be an empty string.
It is the first portion that is wanted, so it is selected by its index of zero, and as the function removes the pattern it splits at, "OCAT Data\DBS" is added.

\subsubsection{Building List of CSV Files}
\begin{stylePy}
listfile	=	[]

for paths, folders, files in os.walk(droppedPath):
	for file in files:
		if file.startswith("OCAT-") and file.endswith(".csv"):
			listfile.append((str(paths).replace(RelPath, "") + "\\" + str(file)).replace("\\\\", "\\"))
\end{stylePy}

Now the chaos that is this script begins.
First the \textbf{listfile} variable is created and its value is an empty list, indicated by [].
Next we have a curious \textbf{for} loop and another function that is very special, and a great source of frustration for me; \textbf{os.walk}.

To put it simply, the \textbf{os.walk} function will walk through the folders and sub-folders of the path it is given.
That sounds nice, but then what is the purpose of the \textbf{for} loop?
Frustratingly, \textbf{os.walk} is not a function that provides an output but something called a generator function, and the loop is necessary to get the information like the path, list of folders and sub-folders in a path, and the files within each folder it walks into.
Yes, there are three outputs from \textbf{os.walk} when used, which is why there are three variables created by the \textbf{for} loop for iterating through the outputs.
I have these named \textbf{paths}, \textbf{folders}, and \textbf{files}, and if you want the complete path to any file it would be the combination of \textbf{paths} and \textbf{files}, and as that is the information I am interested in, \textbf{folders} goes unused.

By the way, the \textbf{os} portion of this function's name identifies that it comes from the \textbf{os} module I imported at the start of the file.
Similarly, the \textbf{sys} of the \textbf{sys.argv} variables indicates Python is to look to the imported \textbf{sys} module.

I now start another \textbf{for} loop, with this one going through the individual files found by the \textbf{os.walk} function.
Within the loop the first thing to do is check the file is an OCAT file, which is fairly easy because they always start with "OCAT-" and Python just happens to have a command that checks if a string starts with a certain pattern, aptly called \textbf{startswith} 
The "OCAT-" pattern could be present elsewhere in the string without resulting in a TRUE result.
By using the \textbf{endswith} function as well, we can make sure the file is a CSV.

When it is an OCAT file found, a string of the path and file name will be added to the \textbf{listfile} variable, but first there will be some changes made to the string.
One is the removal of the \textbf{RelPath} value, which is the path to the OCAT Data folder.
Another change is that just in case there was any accidental doubling of the \SBS characters, the doubles will be replaced with singles.

\subsubsection{Separating Directory/File Names}
\begin{stylePy}
listsplit	=	[file.split("\\") for file in listfile]
\end{stylePy}

Now this is a curious construction and honestly I tend to forget it is a feature of Python.
It is just so different from what I am familiar with in scripts I forget it is a thing, but it works and is nicely compact.
What this basically does is execute the \textbf{split} function on every entry in the \textbf{listfile} variable, and then that output is saved to the new \textbf{listsplit} variable.
The exact construction is the thing I usually forget, but it seems to work by first declaring the command to be run, in this case \textbf{split} on the \textbf{file} variable, but then after this is when the \textbf{for} loop is declared and that \textbf{file} is the variable for iterating.
The fact it is all in square brackets is undoubtedly important to ensuring it is interpreted and executed correctly.
This splitting of the file names and paths is going to be very important for the following steps, which are also going to get a little complicated.

\subsubsection{Mapping Configuration Information}
\begin{stylePy}
listmap	=	[]
for line in listsplit:
	listmapL	=	[line[0], "", "", ""]
	for i in range(1, len(line)):
		listmapL[len(listmapL) - i] = line[len(line) - i]
	listmap.append(listmapL)
\end{stylePy}

Starting this off we have \textbf{listmap} created and then we get to the interesting part of the \textbf{for} loop, and it is in here I want to explain what \textbf{listmap} is and why it is named that.

The outer \textbf{for} loop is going to go through each line in the \textbf{listsplit} object that was just made and do stuff.
The first thing it does is make a variable, \textbf{listmapL}, which stands for listmap Line that is a list with four elements to it.
The first element here is also the first element of the \textbf{listsplit} line, and this will be the GPU.
Remembering the folder tree I use, the top folder under the OCAT Data folder, which was removed earlier via \textbf{RelPath}, is the GPU folder.
If there is an API folder, the second folder is that, and the third is the quality.
The final element is the file name itself, but you may have just spotted the little problem I can have.
"If there is an API folder," is the issue because sometimes there is an API folder, but most of the time there is not, so I need this script to handle that, and that is what this list map structure is for.

After creating \textbf{listmapL}, there is a new \textbf{for} loop that will go through the elements in the original line.
To do this I am using the \textbf{range} function, which will generate a sequence of numbers, with a step of 1, from the first argument to the second.
The step can be changed, but I want it to be one so this default is fine.
The important thing is that the first argument is 1, but Python actually starts its indexing at 0.

The code within the \textbf{for} loop is a little odd to look at because it goes backwards as I am subtracting \textbf{i}, but by being backwards it is beautiful, at least to me.
Regardless of if an API folder is present, the last element in the line will be the CSV file name, and the second to last will be the Quality.
If there is an API folder, it is third to last, but if there is not, then this loop stops.
If there is an API folder, then its name is placed in \textbf{listmapL} and the loop stops there.
Remember, Python starts its indexing at 0, so because this inner \textbf{for} loop has a range starting at 1, it will never reach the GPU folder, and that is the beauty of going backwards.
The ends of the line are independent of the presence of API testing, so by working from both ends, I do not need to worry about this variable in the process.
By using the \textbf{len} function to get the length of the line, I also do not need to worry about using an invalid index.

Ultimately, the output of this inner \textbf{for} loop is a list with four elements with the first always being the GPU, the second always being the API, the third being Quality, and the fourth the CSV file name.
If there is no API, that element is empty and that can be easily handled.
This output is \textbf{listmapL} and outside the inner loop it is appended to \textbf{listmap}, which will continue to be built until all of the lines in \textbf{listsplit} have been properly mapped.

This proper mapping is very important because it is also a fixed structure and that makes manipulating it much easier for the rest of this script.
Unfortunately, the manipulations to come are still pretty convoluted, but they would be far worse without a standardized \textbf{listmap}.

\subsubsection{Finding Configuration Descriptors}
\begin{stylePy}
GPUs, APIs, QUAs	=	[], [], []
GPUsread	=	[]

for item in listmap:
	GPUs.append(item[0])
	APIs.append(item[1])
	QUAs.append(item[2])
\end{stylePy}

Exactly as we have been seeing, I am first creating variables, and these variables need to be lists, so they are empty lists here.
I am doing it in a slightly fancy way though, providing a list of variables and then a list of values for them.
There is also another variable, \textbf{GPUsread} being made but is separate from the others because its purpose is a little different.
Its purpose is to keep track of the GPU names that were read, hence its name, and this is necessary for the multi-API situation.
Normally the MULTI situation will not mark what the current GPU, but I do want that for this situation, and this addresses the problem.

The \textbf{for} loop now goes through \textbf{listmap} to build lists of the GPUs, APIs, and qualities in it.
There will be duplicates in these lists, but the next piece of code addresses this, and the differences the of single and multi-GPU scenarios.

\subsubsection{Finding Unique Descriptors}
\begin{stylePy}
GPUs		=	list(set(GPUs))
APIs		=	list(set(APIs))
if		TYPE	==	"MULTI":
	QUAs	=	[mQUA]
elif	TYPE	==	"SINGLE":
	QUAs	=	list(set(QUAs))
\end{stylePy}

The way Python can be made to address duplicates in a list is to make it a set, which is what we see in that first line as if makes \textbf{GPUs} into a set.
It then converts this set, containing just the unique GPU names, then back to a list to be stored as \textbf{GPUs} again.
This process is repeated for the \textbf{APIs} variable but cannot always be the case for the \textbf{QUA} variable holding the Quality names.

When working with a "MULTI" situation, whether that is multiple GPUs or multiple APIs, there can be multiple Quality levels involved, but I want only a specific level, so when \textbf{TYPE} is "MULTI" its value will be the \textbf{mQUA} manually set earlier.
If this is a "SINGLE" situation though, then the data will be for a single Quality level, so \textbf{QUAs} will be made into just that with the same process I used for finding the unique GPU and API names.

You may look at this structure I have here and find it a little odd, because with \textbf{TYPE} only having two possible values, there is no need to use \textbf{elif} as just \textbf{else} would do.
Consider it future-proofing as by using \textbf{elif} I can add new \textbf{TYPE} values, or consider it a way to clearly state what should happen for both values of the variable.
Either way, there is nothing wrong with using \textbf{elif} instead of \textbf{else}.

I do feel like addressing that this block of code is one that has definitely changed since I originally wrote this article.
It is now completely working with the information it reads, whereas before the list of GPUs was manually set and it would also read a file to get the API names.
The explicit GPU list allowed me to control the order the folders are gone through, but that is hardly necessary.

The API names no longer being read from a file is partly because I have changed the script such that this Python script does not need to provide the list of APIs to the R scripts; it can now read that information itself.
While one could say it was not necessary to read the information from a file anyway, this is incorrect for one reason, and that is the ordering of the API.
I want to be able to control it and previously this Python script would write the list from the file, with the ordering, into the appropriate R script.
That is not necessary now.

\subsubsection{Building CSV Groups for R}
\begin{stylePy}
grouped	=	[]
out		=	""

for GPU in GPUs:
	for API in APIs:
		for QUA in QUAs:
			filelist	=	[]
			for file in listmap:
				if file[0] == GPU	and file[1] == API	and file[2] == QUA:
					filelist.append(file[3])
			if	filelist != []:
				grouped.append([GPU, API, QUA, filelist])
				countCSV	=	len(fileList)
				out	=	out + "\n" + CSVlistR(GPU, API, QUA, filelist)
\end{stylePy}

Among the reasons I decided to do this article, and these scripting sections, was to effectively perform an audit of the code, making improvements of one kind or another.
The part of the code I have reached here I have been reworking for a bit now, which also means I have had to rewrite this part of the section covering it.
I think I am satisfied with it currently, and hope that will remain the case.
For a little context, the code now does two things at the same time that previously I was doing in two separate code blocks.
Because of how little data is being worked with, I doubt the process is meaningful faster this way, but it is still the more efficient solution.
Also, I am aware that one of the things being done is not necessary, but it can be nice to have for troubleshooting nonetheless, so I am keeping it.

Two variables are created first, with one being a list named \textbf{grouped} and the other is a string named \textbf{out}.
It is the \textbf{grouped} variable that is not necessary, but could be useful to examine in case something breaks.
(Previously the code had separate blocks for creating the final versions of these variables, which was indeed helpful for finding and fixing issues when I was originally writing the script.)

A series of \textbf{for} loops are created in order to build every configuration of GPU, API, and Quality.
There can be situations where not every configuration has CSVs associated with it, such as when testing performance with NVIDIA RTX or Microsoft DXR is enabled, as not all of the GPUs I have support these features.
(I treat these features like additional APIs in the folder structure.)

After initiating these \textbf{for} loops I create a new empty list named \textbf{filelist}, which exists to hold the list of CSVs for a given configuration.
By placing this at the start of the code block for the \textbf{for} loops, it will be wiped each time the configuration changes.

Following this variable being created is another \textbf{for} loop for going through the \textbf{listmap} variable.
Next a complex \textbf{if} statement is used to identify just the files that have the current configuration from the earlier \textbf{for} loops.
The file name is then added to the \textbf{filelist} variable.

Once the loop finishes going through the \textbf{filemap} list, the \textbf{filelist} variable will be complete for the current configuration.
Instead of having \textbf{filelist} immediately applied to where it needs to be, an \textbf{if} statement is used to make sure files were actually found.
If they were, then \textbf{filelist} is added to \textbf{grouped} and the \textbf{out} string is expanded with the addition of the output from the \textbf{CSVlistR} custom function made earlier.
A \textbf{countCSV} variable is also made here and set to be the length of the \textbf{filelist} variable.
This variable is used later.

It might be worth noting that the structure of \textbf{grouped} does not match that of the folders, with multiple CSVs listed for each configuration as opposed to the configuration being explicitly stated for each CSV.
At one point that was my desire, but to put it simply, for me to create such a multi-dimensional tree structure would require code far messier than the tree structure would be elegant.
The code, as it is now, is somewhat elegant, so I will take that.

The next several blocks of code are for getting useful information and assigning it to appropriate variables for placing in the R scripts.

\subsubsection{Finding Game/Article Title}
\begin{stylePy}
droppedGame	=	RelPath.rsplit("\\", 3)[1]	\
	.replace(" Performance Analysis", "")	\
	.replace(" Review", "")
\end{stylePy}

This code is for finding the name of the game, or article.
The way it works is actually fairly simple by taking advantage of the \textbf{RelPath} variable created earlier.
This is the path to the OCAT Data folder, which is always contained in the folder for the current project, whether that is a performance analysis, review, or article like this.
Using \textbf{rsplit} the variable is split into the path leading to the project's folder, the project folder name, and then OCAT Data, so the second element (index 1) is always the name of the project.

After getting this name I then escape the line break so I can have a couple \textbf{replace} functions on a different tab level.
This makes it a bit easier to read, in my opinion, and fortunately Python is not complaining about this.
The \textbf{replace} functions are to remove the article type from the folder name, leaving just the name of the game.
As I mentioned earlier, I place Review and Performance Analysis in the folder names to identify the article type, following the game name, so removing this label leaves that name.
For projects like this, however, the title is different, but I also feel it is appropriate to use the project name instead of the game name, as I am not always testing the performance of a game, but something more specific, like the API performance in this case.
I can also manually change this in the appropriate R scripts.

\subsubsection{Reading Locations.txt File}
\begin{stylePy}
if	"Locations.txt" in os.listdir(RelPath):
	loc	=	open(RelPath + "Locations.txt", 'r').readlines()
	loc	=	[line.strip('\n') for line in loc]
else:
	loc	=	["Recording "] * countCSV
	for i in range(countCSV):
		loc[i]	=	loc[i] + str(i+1)
locStr	=	listclean(loc)
\end{stylePy}

This code is fairly similar to what was used for loading in the APIs.txt file earlier, but there are some key differences.
For one, if the text file does not exist, it needs to generate its own list as the location names are not provided by folder names or anything else.
The whole point of the Locations.txt file is to have a record of the locations the data is from that can be read by this script, so usually it will be present.
When it is not, first it creates a list that repeats the string "Recording " as many times as the value of \textbf{countCSV}.
The number of CSVs for each configuration should be the same for all configurations.
After this, a \textbf{for} loop is used to add the correct number to the end of these strings.

Once it has a list of locations stored to \textbf{loc}, or a generic list to identify the recordings, the \textbf{listclean} function is used to create a version of the list suitable for R.
This string is stored in the \textbf{locStr} variable, which will have its contents added to the R scripts later.

\subsubsection{Reading 'Locations Short.txt' File}
\begin{stylePy}
if	"Locations Short.txt" in os.listdir(RelPath):
	locsho		=	open(RelPath + "Locations Short.txt", 'r').readlines()
	locsho		=	[line.strip('\n') for line in locsho]
	locshoStr	=	listclean(locsho)
else:
	locshoStr	=	"NULL"
\end{stylePy}

Being able to provide accurate names for the locations I make recordings in is important, but sometimes the names are so long that they break out of the formatting of the graphs.
To address this I set it up so I could also supply short versions of the location names, and this is the code for finding the appropriate file and reading its contents.
The list of shorter names is then assigned to the \textbf{locshoStr} variable.

\subsubsection{Setting Current GPU}
\begin{stylePy}
if		TYPE	==	"MULTI" and len(GPUs) != 1:
	cGPU	=	"NULL"
elif	TYPE	==	"SINGLE" or len(GPUs) == 1:
	cGPU	=	"\"" + str(GPUs[0]) + "\""
\end{stylePy}

The \textbf{cGPU} variable stands for current GPU and this \textbf{if...elif} statement is necessary because it does not make sense when working with multi-GPU data.
However, there is the single-GPU, multi-API situation that makes things a little more complicated, so now there are two conditions for both parts of the statement.
The first checks for if \textbf{TYPE} is "MULTI" and if there are multiple elements in the \textbf{GPUs} list.
When both of these conditions are True, then the \textbf{cGPU} value will be "NULL," a special value in R.

The second part with \textbf{elif} also has two conditions, but either can be True for it to work.
The first condition is for \textbf{TYPE} to be "SINGLE" and the other is for if there is only one GPU in the \textbf{GPUs} list generated from the file paths.
The latter condition is necessary for the multi-API situation as it has a \textbf{TYPE} of "MULTI."

\subsubsection{Identifying Reference and Output Script, and R Path Format Conversion}
\begin{stylePy}
scriptFull	=	scriptPath + "OCAT - Combined - PA.r"

outputName	=	"Combined - PA - " + droppedGame + ".r"
outputFull	=	droppedPath + "@" + outputName

RPath		=	droppedPath.replace("\\", "/")
\end{stylePy}

We will see code similar to this later on.
Its purpose is to create paths and names to the reference and output R scripts.
The \textbf{scriptFull} variable is the full path and name to the reference R script.
The \textbf{outputName} will be the file name for the output script and then \textbf{outputFull} is the full path for the output script.
The @ symbol is added because when I was originally creating the scripts that combine the CSV data into a single file, and then processing that single file, I wanted to distinguish them from the other scripts I had.
By using this symbol, they not only stand out but are placed at the top of the list when sorted alphabetically.

The \textbf{RPath} variable is there to convert the formatting of the path to the dropped file to what R requires.

\subsubsection{Converting Reference Script (OCAT - Combined - PA.r)}
\begin{stylePy}
if not os.path.exists(outputFull):
	with open(scriptFull, 'r') as fref, open(outputFull, 'w') as fout:
		for line in fref:
			fout.write(line	\
				.replace("!PATH!",		RPath)			\
				.replace("!GAME!",		droppedGame)	\
				.replace("!LONG!",		out)			\
				.replace("!QUA!",		QUAs[0])		\
				.replace("!LOC!",		locStr)			\
			)
		fout.close()
\end{stylePy}

This code is for creating a new script based on the reference script, but the first thing it does is check if the output script already exists.
This is accomplished by using the \textbf{os.path.exists} function, which checks to see if something exists at the path provided.
By using \textbf{not}, the check will be True when the path does not point to anything, and False if it does, meaning the file already exists.

The \textbf{with} command is something fairly powerful, as it was created to provide a cleaner means of dealing with situations involving context managers, such as opening a file.
This means less needs to be explicitly stated.
To be completely honest though, I am using it because when I was looking up how to open and read files in Python to edit their contents, it was used in every example.

Anyway, the remainder of the line uses the \textbf{open} function to open first the reference script for reading, and holding that in the \textbf{fref} (file reference) variable, and then open an output file to write to, holding that in \textbf{fout} (file output).

Next a \textbf{for} loop is started to work through the lines in reference file.
Within the loop the lines from \textbf{fref} are written to \textbf{fout} but with some replacements made.
To identify what is to be replaced in the R scripts, I use clears name in all caps and surround them in exclamation points.
There is no reason I would use this formatting for anything else, so it works well enough, though there is one exception we will see later.
By escaping the line breaks in the script, I have each \textbf{replace} command on its own line, which makes it much easier to read.
The order of these does not matter, as there is no overlap between terms.
The only thing that might be an issue is replacing !QUA!
with the first element in the \textbf{QUAs} list, but because of how I use the scripts and how !QUA!
is used, this is not significant.
That is only used for naming the combined CSV file and I only combine data of the same quality, so the lack of an ability to cycle through the elements is not an issue.

After the loop finishes, \textbf{fout} is told to close, which will save the new script with the replacements made in it.

\subsubsection{Converting Reference Script (OCAT - Combined - Input.r)}
\begin{stylePy}
scriptFull	=	scriptPath + "OCAT - Combined - Input.r"

outputName	=	"Combined - Input - " + droppedGame + ".r"
outputFull	=	droppedPath + "@" + outputName

if not os.path.exists(outputFull):
	with open(scriptFull, 'r') as fref, open(outputFull, 'w') as fout:
		for line in fref:
			fout.write(line
				.replace("!PATH!",		RPath)				\
				.replace("!GAME!",		droppedGame)		\
				.replace("!QUA!",		QUAs[0])			\
				.replace("!GPU!",		cGPU)
			)
		fout.close()
\end{stylePy}

I doubt it is necessary to explain much here, as it is effectively the same form as above.
It is different from the original version of the article though, as I have removed the \textbf{replace} functions that are no longer necessary because the R script loads in the data itself.

This code is for creating the Input.r script, which I will cover in the next section and is quite important.
I use a modular scripting approach, so everything unique to the situation is controlled by the Input.r script, so things like names, whether I want graphs, and other controls are set there and then passed to the Output.r script, which will be taken care of last.

\subsubsection{Copying OCAT - Combined - Output.r}
\begin{stylePy}
if not os.path.exists(droppedPath + "@Combined - Output.r"):
	shutil.copyfile(scriptPath + "OCAT - Combined - Output.r", droppedPath + "@Combined - Output.r")
\end{stylePy}

Finally a command to justify the loading of the \textit{shutil} module, and it is just for copying a file.
At this point I have abstracted the Output.r script enough that absolutely no replacements are needed for it to function.
Everything that may be specific to the situation is controlled by Input.r and Output.r just works on whatever is passed to it.
This is very helpful because it means I could change the formatting the graphs, for example, and by just dropping in the new version of this script, the newer graphs will be generated without any other tweaking, like setting names.

Except for a commented out line to pause the script, for some troubleshooting purposes, this concludes the Python script.
As complicated as it may have been, I have actually cleaned it up some while working on this section, and can even see some ways to make it a little cleaner, but sometimes a little mess helps to keep things straight in my mind, and can provide some teaching opportunities too.
Next up is the Input.r script, which has been significantly updated since this article released.